import requests
import re
import os
from datetime import datetime, timedelta
import json
import xml.etree.ElementTree as ET
import openai
from dotenv import load_dotenv
import time
import argparse
from database import get_db_connection, get_database_config

# åƒè€ƒ comment_summarize_llm.pyï¼Œè¼‰å…¥ .env
load_dotenv()
OUTPUT_DIR = "outputs/forum_threads"
os.makedirs(OUTPUT_DIR, exist_ok=True)

# è§£æåƒæ•¸
parser = argparse.ArgumentParser()
parser.add_argument('--lang', choices=['zh-tw', 'en'], default='zh-tw', help='æ¨è«–èªè¨€')
args = parser.parse_args()
lang = args.lang

PROMPT_HEADER = {
    'zh-tw': "ä½ æ˜¯ä¸€ä½æ¡ŒéŠåˆ†æå¸«ï¼Œè«‹æ ¹æ“šä¸‹åˆ—è¨è«–ä¸²å…§å®¹ï¼Œæ¨è«–è©²éŠæˆ²è¿‘æœŸä¸Šæ¦œçš„å¯èƒ½åŸå› ã€‚å¯åƒè€ƒçš„å¸¸è¦‹åŸå› æœ‰ï¼š1. æ–°éŠæˆ²ä¸”æœ‰æ½›åŠ› 2. æ–°ç‰ˆæœ¬ 3. å…¬å¸å€’é–‰ 4. å‡ºè²¨ 5. å„ç¨®çˆ­è­°(ç¾è¡“ã€æŠ„è¥²ã€å…¬é—œå•é¡Œç­‰ç­‰)\nè«‹ç”¨ç¹é«”ä¸­æ–‡ç°¡æ½”ã€å°ˆæ¥­åœ°ä»¥ä¸€æ®µæµæš¢æ•˜è¿°ï¼Œç›´æ¥èªªæ˜æœ€é—œéµçš„ä¸Šæ¦œåŸå› ï¼Œé¿å…æ¢åˆ—å¼ã€é¿å…è´…è©èˆ‡é–‹å ´ç™½ã€‚",
    'en': "You are a board game analyst. Based on the following forum threads, infer the most likely reason why this game recently became hot. Common reasons include: 1. New and promising game 2. New edition 3. Publisher bankruptcy 4. Shipping 5. Controversies (art, plagiarism, PR, etc.)\nPlease write a concise, professional, and fluent English paragraph directly stating the key reason for the ranking. Avoid bullet points, filler, and introductions."
}

# DB é€£ç·š
conn = None
cursor = None

# è¨­å®š requests é‡è©¦æ©Ÿåˆ¶
session = requests.Session()
session.headers.update({'User-Agent': 'BGG Forum Threads Fetcher 1.0'})

def fetch_forum_list(objectid):
    """æŠ“å–éŠæˆ²çš„è¨è«–å€åˆ—è¡¨"""
    try:
        url = f"https://boardgamegeek.com/xmlapi2/forumlist?id={objectid}&type=thing"
        response = session.get(url, timeout=10)
        if response.status_code != 200:
            print(f"âš ï¸ ç„¡æ³•å–å¾—è¨è«–å€åˆ—è¡¨ objectid={objectid}, status={response.status_code}")
            return []

        root = ET.fromstring(response.content)
        forums = []
        for forum in root.findall('.//forum'):
            forum_id = forum.get('id')
            title = forum.get('title', '')
            if forum_id and title:
                forums.append({'id': forum_id, 'title': title})
        return forums
    except Exception as e:
        print(f"âš ï¸ æŠ“å–è¨è«–å€åˆ—è¡¨å¤±æ•— objectid={objectid}: {e}")
        return []

def fetch_forum_threads(forum_id, max_threads=5):
    """æŠ“å–è¨è«–å€çš„è¨è«–ä¸²åˆ—è¡¨"""
    try:
        url = f"https://boardgamegeek.com/xmlapi2/forum?id={forum_id}"
        response = session.get(url, timeout=10)
        if response.status_code != 200:
            print(f"âš ï¸ ç„¡æ³•å–å¾—è¨è«–ä¸²åˆ—è¡¨ forum_id={forum_id}, status={response.status_code}")
            return []

        root = ET.fromstring(response.content)
        threads = []
        for thread in root.findall('.//thread')[:max_threads]:
            thread_id = thread.get('id')
            subject = thread.get('subject', '')
            lastpostdate = thread.get('lastpostdate', '')
            if thread_id and subject:
                threads.append({
                    'id': thread_id,
                    'subject': subject,
                    'lastpostdate': lastpostdate
                })
        return threads
    except Exception as e:
        print(f"âš ï¸ æŠ“å–è¨è«–ä¸²åˆ—è¡¨å¤±æ•— forum_id={forum_id}: {e}")
        return []

def fetch_thread_posts(thread_id, max_posts=3):
    """æŠ“å–è¨è«–ä¸²çš„æ–‡ç« å…§å®¹"""
    try:
        url = f"https://boardgamegeek.com/xmlapi2/thread?id={thread_id}&count={max_posts}"
        response = session.get(url, timeout=10)
        if response.status_code != 200:
            print(f"âš ï¸ ç„¡æ³•å–å¾—è¨è«–ä¸²å…§å®¹ thread_id={thread_id}, status={response.status_code}")
            return []

        root = ET.fromstring(response.content)
        posts = []
        for article in root.findall('.//article'):
            username = article.get('username', '')
            postdate = article.get('postdate', '')
            body_elem = article.find('body')
            body = body_elem.text if body_elem is not None else ''

            # æ¸…ç† HTML æ¨™ç±¤
            if body:
                body = re.sub(r'<[^>]+>', '', body)
                body = body.strip()[:200]  # é™åˆ¶é•·åº¦

            if username and body:
                posts.append({
                    'author': username,
                    'postdate': postdate,
                    'body': body
                })
        return posts
    except Exception as e:
        print(f"âš ï¸ æŠ“å–è¨è«–ä¸²å…§å®¹å¤±æ•— thread_id={thread_id}: {e}")
        return []

# æŸ¥è©¢ i18n æ˜¯å¦å·²æœ‰ç¿»è­¯ä¸”æœªéæœŸ
def is_i18n_fresh(objectid, lang, days=7):
    cursor.execute("SELECT updated_at FROM forum_threads_i18n WHERE objectid = ? AND lang = ?", (objectid, lang))
    row = cursor.fetchone()
    if row and row[0]:
        try:
            dt = datetime.fromisoformat(row[0])
            if datetime.utcnow() - dt < timedelta(days=days):
                return True
        except Exception:
            pass
    return False

def summarize_reason_with_llm(game_name, threads):
    # è‹¥æ²’æœ‰è¨è«–ä¸²ï¼Œç”¢ç”Ÿé è¨­å›æ‡‰
    if not threads:
        if lang == 'zh-tw':
            return f"å› ç‚ºè¨è«–è³‡æ–™éå°‘ï¼Œç„¡æ³•æ¨è«– {game_name} çš„ä¸Šæ¦œåŸå› ã€‚"
        else:
            return f"Unable to infer the reason for {game_name}'s popularity due to insufficient discussion data."

    # æª¢æŸ¥è¨è«–ä¸²å…§å®¹æ˜¯å¦éå°‘ï¼ˆä¾‹å¦‚ï¼šè¨è«–ä¸²æ•¸é‡å°‘æ–¼2å€‹ï¼Œæˆ–ç¸½ç•™è¨€æ•¸å°‘æ–¼3å€‹ï¼‰
    total_posts = sum(len(t.get('posts', [])) for t in threads)
    if len(threads) < 2 or total_posts < 3:
        if lang == 'zh-tw':
            return f"å› ç‚ºè¨è«–è³‡æ–™éå°‘ï¼Œç„¡æ³•æ¨è«– {game_name} çš„ä¸Šæ¦œåŸå› ã€‚"
        else:
            return f"Unable to infer the reason for {game_name}'s popularity due to insufficient discussion data."

    # è‹¥ lang == 'en' ä¸” threads å…¨ç‚ºè‹±æ–‡ï¼Œç›´æ¥çµ„åˆ reason
    if lang == 'en' and threads and all(is_english_thread(t) for t in threads):
        # ç›´æ¥ç”¨ç¬¬ä¸€å€‹è¨è«–ä¸²æ¨™é¡Œèˆ‡å‰å¹¾å‰‡ç•™è¨€çµ„åˆä¸€æ®µè‹±æ–‡ reason
        reason = f"Key discussion for {game_name}: "
        for t in threads[:1]:
            reason += f"{t['title']}. "
            for p in t['posts'][:2]:
                reason += f"{p['author']}: {p['body'][:80]}. "
        return reason.strip()
    # å¦å‰‡å‘¼å« LLM
    prompt = PROMPT_HEADER[lang] + f"\n\nGame: {game_name}\nForum thread summary:\n"
    for t in threads:
        prompt += f"\n- {t['title']} ({t['postdate']})"
        for p in t['posts'][:2]:
            prompt += f"\n  - {p['author']}ï¼š{p['body'][:80]}"
    try:
        client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        response = client.chat.completions.create(
            model=os.getenv("OPENAI_MODEL", "gpt-3.5-turbo"),
            messages=[{"role": "user", "content": prompt}],
            max_tokens=512,
            temperature=0.5
        )
        reason = response.choices[0].message.content.strip()
    except Exception as e:
        print(f"âš ï¸ LLM è™•ç†å¤±æ•—: {e}")
        if lang == 'zh-tw':
            reason = f"å› ç‚ºè¨è«–è³‡æ–™éå°‘ï¼Œç„¡æ³•æ¨è«– {game_name} çš„ä¸Šæ¦œåŸå› ã€‚"
        else:
            reason = f"Unable to infer the reason for {game_name}'s popularity due to insufficient discussion data."
    return reason

def is_english_thread(thread):
    # åˆ¤æ–·è¨è«–ä¸²æ¨™é¡Œèˆ‡ç•™è¨€æ˜¯å¦ç‚ºè‹±æ–‡ï¼ˆç°¡å–®åˆ¤æ–·ï¼Œé‡åˆ°éè‹±æ–‡å­—æ¯æ¯”ä¾‹éé«˜å‰‡è¦–ç‚ºéè‹±æ–‡ï¼‰
    import string
    def is_english(text):
        letters = sum(1 for c in text if c in string.ascii_letters)
        return letters / max(1, len(text)) > 0.6
    if not is_english(thread['title']):
        return False
    for p in thread['posts']:
        if not is_english(p['body']):
            return False
    return True

def is_threads_expired(objectid, days=7):
    cursor.execute("SELECT MAX(created_at), threads_json FROM forum_threads WHERE objectid = ? ORDER BY created_at DESC LIMIT 1", (objectid,))
    row = cursor.fetchone()
    if not row or not row[0]:
        return True

    # æª¢æŸ¥è¨è«–ä¸²å…§å®¹æ˜¯å¦ç‚ºç©º
    try:
        threads_data = json.loads(row[1]) if row[1] else []
        if not threads_data:  # å¦‚æœè¨è«–ä¸²ç‚ºç©ºï¼Œä¹Ÿè¦–ç‚ºéæœŸ
            return True
    except Exception:
        return True

    # æª¢æŸ¥æ™‚é–“æ˜¯å¦éæœŸ
    try:
        dt = datetime.fromisoformat(row[0])
        return (datetime.utcnow() - dt).days >= days
    except Exception:
        return True

def delete_all_threads_and_i18n(objectid):
    cursor.execute("DELETE FROM forum_threads_i18n WHERE objectid = ?", (objectid,))
    cursor.execute("DELETE FROM forum_threads WHERE objectid = ?", (objectid,))
    conn.commit()

def fetch_and_save_threads(objectid, name):
    """å¯¦éš›æŠ“å–ä¸¦å„²å­˜è¨è«–ä¸²å…§å®¹"""
    print(f"ğŸ” æ­£åœ¨æŠ“å– {name} ({objectid}) çš„è¨è«–ä¸²...")

    # 1. æŠ“å–è¨è«–å€åˆ—è¡¨
    forums = fetch_forum_list(objectid)
    if not forums:
        print(f"âš ï¸ ç„¡è¨è«–å€è³‡æ–™ objectid={objectid}")
        threads = []
    else:
        threads = []
        # 2. å¾å‰å¹¾å€‹è¨è«–å€æŠ“å–è¨è«–ä¸²
        for forum in forums[:3]:  # åªæŠ“å‰3å€‹è¨è«–å€
            time.sleep(1)  # é¿å…è«‹æ±‚éå¿«
            forum_threads = fetch_forum_threads(forum['id'], max_threads=3)

            for thread_info in forum_threads:
                time.sleep(1)  # é¿å…è«‹æ±‚éå¿«
                posts = fetch_thread_posts(thread_info['id'], max_posts=3)

                if posts:  # åªä¿ç•™æœ‰å…§å®¹çš„è¨è«–ä¸²
                    threads.append({
                        'title': thread_info['subject'],
                        'postdate': thread_info['lastpostdate'],
                        'posts': posts
                    })

                if len(threads) >= 5:  # é™åˆ¶ç¸½è¨è«–ä¸²æ•¸é‡
                    break

            if len(threads) >= 5:
                break

    # 3. å„²å­˜åˆ°è³‡æ–™åº«
    cursor.execute("""
        INSERT INTO forum_threads (objectid, name, threads_json, snapshot_date, created_at)
        VALUES (?, ?, ?, ?, ?)
    """, (objectid, name, json.dumps(threads, ensure_ascii=False), datetime.utcnow().strftime("%Y-%m-%d"), datetime.utcnow().isoformat()))
    conn.commit()

    print(f"âœ… å·²æŠ“å– {len(threads)} å€‹è¨è«–ä¸² objectid={objectid}")
    return threads

def get_threads_by_objectid(objectid):
    cursor.execute("SELECT threads_json FROM forum_threads WHERE objectid = ? ORDER BY created_at DESC LIMIT 1", (objectid,))
    row = cursor.fetchone()
    if row:
        return json.loads(row[0])
    return []

def main():
    today = datetime.utcnow().strftime("%Y-%m-%d")
    output_path = f"{OUTPUT_DIR}/forum_threads_{today}.json"
    # æª¢æŸ¥æ˜¯å¦å·²æœ‰æª”æ¡ˆä¸”æ™‚é–“å°æ–¼ 7 å¤©
    if os.path.exists(output_path):
        mtime = os.path.getmtime(output_path)
        if time.time() - mtime < 7 * 24 * 60 * 60:
            print(f"â© {output_path} å·²å­˜åœ¨ä¸”è·ä»Šæœªæ»¿ 7 å¤©ï¼Œç›´æ¥è·³éã€‚")
            return

    # ç²å–éœ€è¦è™•ç†çš„éŠæˆ²ï¼šæ–°é€²æ¦œ + æ²’æœ‰è¨è«–ä¸²è³‡æ–™çš„éŠæˆ²
    def get_games_to_process():
        # 1. æ–°é€²æ¦œçš„éŠæˆ²
        cursor.execute("SELECT DISTINCT snapshot_date FROM hot_games ORDER BY snapshot_date DESC LIMIT 2")
        rows = cursor.fetchall()
        new_games = []
        if len(rows) >= 2:
            today, yesterday = rows[0][0], rows[1][0]
            cursor.execute("SELECT objectid, name FROM hot_games WHERE snapshot_date = ?", (today,))
            today_list = cursor.fetchall()
            cursor.execute("SELECT objectid FROM hot_games WHERE snapshot_date = ?", (yesterday,))
            yesterday_ids = [r[0] for r in cursor.fetchall()]
            new_games = [(oid, name) for oid, name in today_list if oid not in yesterday_ids]

        # 2. ä»Šæ—¥æ¦œä¸Šä½†æ²’æœ‰è¨è«–ä¸²è³‡æ–™æˆ–ç¿»è­¯çš„éŠæˆ²
        cursor.execute("""
            SELECT h.objectid, h.name
            FROM hot_games h
            WHERE h.snapshot_date = (SELECT MAX(snapshot_date) FROM hot_games)
            AND (
                h.objectid NOT IN (SELECT DISTINCT objectid FROM forum_threads)
                OR h.objectid NOT IN (SELECT DISTINCT objectid FROM forum_threads_i18n WHERE lang = ?)
            )
        """, (lang,))
        missing_games = cursor.fetchall()

        # åˆä½µä¸¦å»é‡
        all_games = {}
        for oid, name in new_games + missing_games:
            all_games[oid] = name

        return [(oid, name) for oid, name in all_games.items()]

    games_to_process = get_games_to_process()
    all_results = {}

    for objectid, name in games_to_process:
        print(f"Fetching forum threads for {name} ({objectid}) [{lang}] ...")
        # 1. åˆ¤æ–·è¨è«–ä¸²æ˜¯å¦éæœŸæˆ–ä¸å­˜åœ¨
        if is_threads_expired(objectid):
            print(f"â© è¨è«–ä¸²å·²éæœŸæˆ–ä¸å­˜åœ¨ï¼Œé‡æŠ“ä¸¦åˆªé™¤æ‰€æœ‰èªè¨€ reasonï¼šobjectid={objectid}")
            delete_all_threads_and_i18n(objectid)
            threads = fetch_and_save_threads(objectid, name)
        else:
            threads = get_threads_by_objectid(objectid)

        # 2. è‹¥è©²èªè¨€ reason ä¸å­˜åœ¨ï¼Œæ‰ä¸Ÿçµ¦ LLM
        cursor.execute("SELECT 1 FROM forum_threads_i18n WHERE objectid = ? AND lang = ?", (objectid, lang))
        reason_exists = cursor.fetchone() is not None
        if reason_exists:
            print(f"â© å·²æœ‰æ–°é®® {lang} reasonï¼Œè·³é objectid={objectid}")
            continue

        # 3. ç”¨ç¾æœ‰ threads ç”¢ç”Ÿ reason
        reason = summarize_reason_with_llm(name, threads)
        cursor.execute("""
            INSERT INTO forum_threads_i18n (objectid, lang, reason, updated_at)
            VALUES (?, ?, ?, ?)
            ON CONFLICT(objectid, lang) DO UPDATE SET reason=excluded.reason, updated_at=excluded.updated_at
        """, (objectid, lang, reason, datetime.utcnow().isoformat()))
        all_results[objectid] = {
            "name": name,
            "threads": threads,
            "reason": reason
        }

    conn.commit()
    conn.close()
    # å„²å­˜ debug æª”æ¡ˆ
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(all_results, f, ensure_ascii=False, indent=2)

if __name__ == "__main__":
    main()